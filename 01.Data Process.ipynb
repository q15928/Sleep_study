{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data are collected from ~70 insomnia patients who attended the Woolcock sleep clinic and had their sleep monitored via sophisticated equipment. The data are the following 4 time-series streams:\n",
    "* **Sleep staging**: a classification of each 30s window (epoch) in the PSG data. This is the ground truth\n",
    "* **Heart rate**: measured at beat-by-beat interval in milliseconds\n",
    "* **Skin temperature**: measured the skin temperature at different parts of the body at every 15s\n",
    "* **Actigraphy**: measured the amount of activity plus the amount of light every 30s\n",
    "\n",
    "**Goal: Extract, clean and align all the data to the timestamp of sleep staging**\n",
    "\n",
    "### Some challenges of time-series data\n",
    "* Measurements at different interval with uneven length\n",
    "* Measurements starting at different time\n",
    "* Missing data in between \n",
    "\n",
    "### Data processing procedure\n",
    "1. Extract the data from different sources and files\n",
    "2. Clean and manipulate the data to proper data type\n",
    "3. Resample heart rate and skin temperature to 30s interval\n",
    "4. Truncate and align all the data to the timestamp of sleep staging data\n",
    "\n",
    "Pandas has a comprehensive set of tools to work with time-series data (http://pandas.pydata.org/pandas-docs/stable/timeseries.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas.tseries import offsets\n",
    "import numpy as np\n",
    "import os, re, glob, zipfile, tempfile\n",
    "import xlrd\n",
    "import datetime, time\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import matplotlib\n",
    "%matplotlib inline\n",
    "\n",
    "# sns.set(style='whitegrid', context='notebook')\n",
    "matplotlib.style.use('ggplot')\n",
    "pd.set_option('display.max_rows', 15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process sleep staging file\n",
    "The sleep staging file provides the ground truth label for our sleep-wake classification. We will convert wake (SLEEP-S0) as 0, and the rest sleep stages as 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def process_one_staging_file(staging_file):\n",
    "    \"\"\"\n",
    "    Extract epoch data from one sleep staging file, store into dataframe, convert to proper datatypes \n",
    "    and remove NaN.\n",
    "    \n",
    "    Args:\n",
    "        staging_file: path and file name\n",
    "    Return:\n",
    "        pandas dataframe containing the epoch data\n",
    "    \"\"\"\n",
    "    print(\"Processing {0} ...\".format(staging_file))\n",
    "    m = re.search(r\"INS\\s(\\d+)\", staging_file)\n",
    "    if m: \n",
    "        id = m.group(1)\n",
    "        patient_id = \"INS_WI_\" + id\n",
    "    \n",
    "    staging_df = pd.read_csv(staging_file, sep=\"\\t\", header=None, skiprows=14)\n",
    "    staging_df = staging_df.drop([0, 3], axis=1)\n",
    "    staging_df.columns = ['Datetime', 'Staging']\n",
    "#     staging_df['Staging'] = staging_df['Staging'].map(lambda s: 0 if 'S0' in s else 1)\n",
    "    # Convert the datetime as index\n",
    "    staging_df.index = pd.to_datetime(staging_df['Datetime'])\n",
    "    staging_df.index.name = None\n",
    "    staging_df.insert(0, 'Patient_id', patient_id)\n",
    "\n",
    "    staging_df = staging_df.drop('Datetime', axis=1)\n",
    "    staging_df = staging_df.asfreq('30S')\n",
    "    \n",
    "    return staging_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing ./Input/Sleep stages/INS 011-Events.txt ...\n"
     ]
    }
   ],
   "source": [
    "staging_df = process_one_staging_file(\"./Input/Sleep stages/INS 011-Events.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Patient_id</th>\n",
       "      <th>Staging</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2015-10-01 00:57:16</th>\n",
       "      <td>INS_WI_011</td>\n",
       "      <td>SLEEP-S0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-10-01 00:57:46</th>\n",
       "      <td>INS_WI_011</td>\n",
       "      <td>SLEEP-S0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-10-01 00:58:16</th>\n",
       "      <td>INS_WI_011</td>\n",
       "      <td>SLEEP-S0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Patient_id   Staging\n",
       "2015-10-01 00:57:16  INS_WI_011  SLEEP-S0\n",
       "2015-10-01 00:57:46  INS_WI_011  SLEEP-S0\n",
       "2015-10-01 00:58:16  INS_WI_011  SLEEP-S0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "staging_df.head(3)\n",
    "# staging_df.columns\n",
    "# staging_df.info()\n",
    "# staging_df.index.name = None\n",
    "# staging_df.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process heart rate file\n",
    "Heart rate is measure beat-beat interval. It is a txt file for one subject per night. \n",
    "\n",
    "There is one **ONE recording date**. It is required to take care the next day flipping over when the time wraps around the midnight."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def process_one_hr_file(hr_file):\n",
    "    \"\"\"\n",
    "    Extract data from one heart rate file, store into dataframe, convert to proper datatypes \n",
    "    and remove NaN.\n",
    "    \n",
    "    Args:\n",
    "        hr_file: path and file name\n",
    "    Return:\n",
    "        pandas dataframe containing the epoch data\n",
    "    \"\"\"\n",
    "    print(\"Processing {0}...\".format(hr_file))\n",
    "    \n",
    "    # Extract patient_id and recording date\n",
    "    patient_id, re_date = None, None\n",
    "    num_lines = 0\n",
    "    with open(hr_file, \"r\") as f:\n",
    "#         if sum(1 for l in f) < 6: return None\n",
    "        for line in f:\n",
    "            num_lines += 1\n",
    "            if line.find(\"Patient ID\") > -1:\n",
    "                patient_id = line.strip()[-10:]\n",
    "            elif line.find(\"Recording Date\") > -1:\n",
    "                re_date = line.strip()[-(len(line)-len(\"Recording Date: \")):].strip()\n",
    "#             if patient_id and re_date:\n",
    "#                 break\n",
    "\n",
    "    if num_lines < 6: return None\n",
    "#     if '011' in patient_id:\n",
    "#         next_date = (pd.to_datetime(re_date, dayfirst=True)).strftime('%d/%m/%Y')\n",
    "#     else:\n",
    "#         next_date = (pd.to_datetime(re_date, dayfirst=True) + offsets.Day(1)).strftime('%d/%m/%Y')\n",
    "    # read hr records into dataframe\n",
    "    hr_df = pd.read_csv(hr_file, header=None, sep=\"\\t\", skiprows=5)\n",
    "    \n",
    "    # check if the first record is started at \"PM\" or \"AM\"\n",
    "#     print(hr_df.ix[0, 0])\n",
    "    if 'AM' in hr_df.ix[0, 0]:\n",
    "        next_date = (pd.to_datetime(re_date, dayfirst=True)).strftime('%d/%m/%Y')\n",
    "    else:\n",
    "        next_date = (pd.to_datetime(re_date, dayfirst=True) + offsets.Day(1)).strftime('%d/%m/%Y')\n",
    "    \n",
    "    hr_df[0] = hr_df[0].apply(lambda s: re_date + \" \" + s if 'PM' in s else next_date + \" \" + s)\n",
    "    # hr_df['Patient_id'] = patient_id\n",
    "    hr_df['Datetime'] = pd.to_datetime(hr_df[0], dayfirst=True) + hr_df[1].apply(offsets.Milli)\n",
    "    \n",
    "    ## the following doesn't work\n",
    "#     hr_df['Datetime'] = pd.to_datetime(hr_df[0] + \" \" + hr_df[1].to_string(), format='%d/%m/%Y %I:%M:%S %p %f')\n",
    "    hr_df = hr_df.drop([0, 1], axis=1)\n",
    "    hr_df[2] = hr_df[2] / 1000\n",
    "    hr_df.rename(columns={2: \"HR_duration\"}, inplace=True)\n",
    "    hr_df.index = hr_df['Datetime']\n",
    "    hr_df.index.name = None\n",
    "    hr_df.drop('Datetime', axis=1, inplace=True)\n",
    "    \n",
    "    # resampling as 30S to compute the mean and stdev\n",
    "    # hr_df = hr_df.resample('30S').mean()\n",
    "    \n",
    "    return hr_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing ./Input/HRV/011, INSEKG_RR Intervals.txt...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/qfen8290/miniconda3/lib/python3.5/site-packages/pandas/core/ops.py:533: PerformanceWarning: Adding/subtracting array of DateOffsets to Series not vectorized\n",
      "  \"Series not vectorized\", PerformanceWarning)\n"
     ]
    }
   ],
   "source": [
    "hr_df = process_one_hr_file(\"./Input/HRV/011, INSEKG_RR Intervals.txt\")\n",
    "# hr_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HR_duration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2015-10-01 00:53:56.398</th>\n",
       "      <td>0.840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-10-01 00:53:57.237</th>\n",
       "      <td>0.832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-10-01 00:53:58.069</th>\n",
       "      <td>0.825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-10-01 00:53:58.895</th>\n",
       "      <td>0.787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-10-01 00:53:59.682</th>\n",
       "      <td>0.796</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         HR_duration\n",
       "2015-10-01 00:53:56.398        0.840\n",
       "2015-10-01 00:53:57.237        0.832\n",
       "2015-10-01 00:53:58.069        0.825\n",
       "2015-10-01 00:53:58.895        0.787\n",
       "2015-10-01 00:53:59.682        0.796"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hr_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Align HR dataframe to staging dataframe by resampling to 30s interval\n",
    "We need to aggregate the heart rate beat-by-beat interval into 30s epoch and align with the timestamp of sleep staging. Then will compute the mean and standard deviation for each epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def align_hr_df(staging_df, hr_df):\n",
    "    \"\"\"\n",
    "    Align HR dataframe to staging dataframe by resampling to 30S interval\n",
    "    Args:\n",
    "        staging_df:\n",
    "        hr_df:\n",
    "    Return:\n",
    "        aligned_hr_df:\n",
    "    \"\"\"\n",
    "    start = (staging_df.index.min() - offsets.Second(30)).strftime('%Y-%m-%d %H:%M:%S')\n",
    "    end = (staging_df.index.max()).strftime('%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "    aligned_hr_df = hr_df[start:end]\n",
    "    # check if ACT data available to align with sleep staging data   \n",
    "    if len(aligned_hr_df) == 0: return None\n",
    "    \n",
    "    aligned_hr_df = aligned_hr_df.resample('30S', base=staging_df.index.min().second, closed='right', label='right')\\\n",
    "                    .agg({'HR_mean': np.mean, 'HR_stdev': np.std})\n",
    "    aligned_hr_df.columns = aligned_hr_df.columns.droplevel(1)\n",
    "    \n",
    "    return aligned_hr_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HR_mean</th>\n",
       "      <th>HR_stdev</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2015-10-01 00:57:46</th>\n",
       "      <td>0.954478</td>\n",
       "      <td>0.079565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-10-01 00:58:16</th>\n",
       "      <td>0.906577</td>\n",
       "      <td>0.059958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-10-01 00:58:46</th>\n",
       "      <td>0.912030</td>\n",
       "      <td>0.145576</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      HR_mean  HR_stdev\n",
       "2015-10-01 00:57:46  0.954478  0.079565\n",
       "2015-10-01 00:58:16  0.906577  0.059958\n",
       "2015-10-01 00:58:46  0.912030  0.145576"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aligned_hr_df = align_hr_df(staging_df, hr_df)\n",
    "aligned_hr_df.head(3)\n",
    "# aligned_hr_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HR_mean</th>\n",
       "      <th>HR_stdev</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2015-10-01 03:47:16</th>\n",
       "      <td>0.547</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-10-01 06:16:16</th>\n",
       "      <td>1.111</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     HR_mean  HR_stdev\n",
       "2015-10-01 03:47:16    0.547       NaN\n",
       "2015-10-01 06:16:16    1.111       NaN"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aligned_hr_df[(aligned_hr_df['HR_mean'].isnull()==False) & (aligned_hr_df['HR_stdev'].isnull()==True)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process actigraphy file\n",
    "The important part of actigraphy file is **\"epoch-by-epoch\"** section which is the measurement of activity and white light for every 30s. However, the line number of this section varies from file to file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def process_one_act_file(act_file):\n",
    "    \"\"\"\n",
    "    Extract epoch data from one actigraphy csv file, store into dataframe, convert to proper datatypes \n",
    "    and remove NaN.\n",
    "    \n",
    "    Args:\n",
    "        act_file: path and file name\n",
    "    Return:\n",
    "        pandas dataframe containing the epoch data\n",
    "    \"\"\"\n",
    "    print(\"Processing {0}...\".format(act_file))\n",
    "    m = re.search(r\".*/(INS_WI_\\d+).*\\.csv\", act_file)\n",
    "    if m:\n",
    "        patient_id = m.group(1)\n",
    "    else:\n",
    "        return None\n",
    "    rows = []\n",
    "    with open(act_file, \"r\") as f:\n",
    "        is_epoch = False\n",
    "        nu_epoch_start = None\n",
    "        i = 0\n",
    "        for line in f:\n",
    "            i += 1\n",
    "            if line.find(\"Epoch-by-Epoch\") > -1:\n",
    "                is_epoch = True\n",
    "            # elif re.search(r\"\\\"Line\\\",\\\"Epoch\\\",\\\"Day\\\",\\\"Seconds\\\",\\\"Date\\\",\\\"Time\\\"\", line) and is_epoch:\n",
    "            elif is_epoch and line.find(',\"Epoch\",\"Day\",\"Seconds\"') > -1:# and is_epoch:\n",
    "                #print(line)\n",
    "                epoch_columns = line\n",
    "                nu_epoch_start = i + 1\n",
    "                #print(epoch_columns, nu_epoch_start)                \n",
    "                break\n",
    "#             elif is_epoch and len(line) > 1 and nu_epoch_start:\n",
    "#                 fields = line.replace('\"', '').strip().split(sep=\",\")[:-2]\n",
    "#                 fields = tuple([fields[4], fields[5], fields[6], fields[8]])\n",
    "#                 rows.append(fields)\n",
    "                # print(rows)\n",
    "                # break\n",
    "    #act_df = pd.DataFrame.from_records(rows)\n",
    "    act_df = pd.read_csv(act_file, header=None, skiprows=nu_epoch_start)\n",
    "    act_df.drop(act_df.shape[1]-2, axis=1, inplace=True)\n",
    "    \n",
    "    act_df.columns = epoch_columns.replace('\"', '').strip().split(sep=\",\")[:-1]\n",
    "    act_df = act_df[['Date', 'Time', 'Activity', 'White Light']]\n",
    "    for col in act_df.columns:\n",
    "        if sum(act_df[col].isin(['NaN'])) > 1:\n",
    "            act_df[col] = act_df[col].replace('NaN', np.nan)\n",
    "\n",
    "    # drop any rows with NA\n",
    "    act_df = act_df.dropna().reset_index(drop=True)\n",
    "           \n",
    "    # combine Date and Time columns\n",
    "    act_df[\"Datetime\"] = act_df[\"Date\"] +\" \" + act_df[\"Time\"]\n",
    "    act_df[\"Datetime\"] = pd.to_datetime(act_df[\"Datetime\"], dayfirst=True)\n",
    "    act_df = act_df.drop([\"Date\", \"Time\"], axis=1)\n",
    "    \n",
    "    \n",
    "    # insert patient id \n",
    "    # act_df['Patient_id'] = patient_id\n",
    "    # act_df = act_df[['Datetime', 'Activity', 'White Light']]\n",
    "    act_df.index = act_df['Datetime']\n",
    "    act_df.index.name = None\n",
    "    act_df.drop('Datetime', axis=1, inplace=True)\n",
    "\n",
    "    act_df[[\"Activity\", \"White Light\"]] = \\\n",
    "        act_df[[\"Activity\", \"White Light\"]].apply(pd.to_numeric)\n",
    "    \n",
    "    return act_df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def process_multi_act_files(act_path):\n",
    "    \"\"\"\n",
    "    Process multiple actigraphy files for different patients and extract each epoch data for each patient\n",
    "\n",
    "    Args:\n",
    "        act_file_list: a list of actigraphy csv files containing measurement\n",
    "    Return:\n",
    "        pandas dataframe containing the epoch data\n",
    "    \"\"\"\n",
    "    file_format = \"*.csv\"\n",
    "    act_file_list = glob.glob(act_path + file_format)\n",
    "    act_df = pd.DataFrame()\n",
    "    for act_file in act_file_list:\n",
    "        one_act_df = process_one_act_file(act_file)\n",
    "        if not isinstance(one_act_df, type(None)):\n",
    "            act_df = act_df.append(one_act_df, ignore_index=True)\n",
    "        \n",
    "    # drop duplicated entries\n",
    "    act_df.drop_duplicates(inplace=True)\n",
    "    return act_df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing ./Input/Actigraphy/INS_WI_011_20_09_2015_9_00_00_AM_BL_AEM.csv...\n"
     ]
    }
   ],
   "source": [
    "act_df = process_one_act_file(\"./Input/Actigraphy/INS_WI_011_20_09_2015_9_00_00_AM_BL_AEM.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Activity</th>\n",
       "      <th>White Light</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2015-09-20 11:59:30</th>\n",
       "      <td>13.0</td>\n",
       "      <td>90.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-09-20 12:00:00</th>\n",
       "      <td>7.0</td>\n",
       "      <td>148.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-09-20 12:00:30</th>\n",
       "      <td>39.0</td>\n",
       "      <td>114.86</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Activity  White Light\n",
       "2015-09-20 11:59:30      13.0        90.51\n",
       "2015-09-20 12:00:00       7.0       148.96\n",
       "2015-09-20 12:00:30      39.0       114.86"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "act_df.head(3)\n",
    "# act_df.info()\n",
    "# (act_df.index[1] - act_df.index[0]).seconds > 30"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Align ACT dataframe to staging dataframe by resampling to 30s interval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def align_act_df(staging_df, act_df):\n",
    "    \"\"\"\n",
    "    Align ACT dataframe to staging dataframe by resampling to 30S interval\n",
    "    Args:\n",
    "        staging_df:\n",
    "        act_df:\n",
    "    Return:\n",
    "        aligned_act_df:\n",
    "    \"\"\"\n",
    "    if (act_df.index[1] - act_df.index[0]).seconds > 30:\n",
    "        start = (staging_df.index.min() - offsets.Second(60)).strftime('%Y-%m-%d %H:%M:%S')\n",
    "        act_df = act_df / 2\n",
    "    else:\n",
    "        start = (staging_df.index.min() - offsets.Second(30)).strftime('%Y-%m-%d %H:%M:%S')\n",
    "    end = (staging_df.index.max()).strftime('%Y-%m-%d %H:%M:%S')\n",
    "    \n",
    "    aligned_act_df = act_df[start:end]\n",
    "    # check if ACT data available to align with sleep staging data   \n",
    "    if len(aligned_act_df) == 0: return None\n",
    "    \n",
    "    if (aligned_act_df.index[1] - aligned_act_df.index[0]).seconds > 30:\n",
    "        aligned_act_df = aligned_act_df.resample('30S', base=staging_df.index.min().second, closed='right', label='right').ffill()\n",
    "    else:\n",
    "        aligned_act_df = aligned_act_df.resample('30S', base=staging_df.index.min().second, closed='right', label='right').mean()\n",
    "#     aligned_hr_df.columns = aligned_hr_df.columns.droplevel(1)\n",
    "    \n",
    "    return aligned_act_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "aligned_act_df = align_act_df(staging_df, act_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Activity</th>\n",
       "      <th>White Light</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2015-10-01 00:57:16</th>\n",
       "      <td>98.0</td>\n",
       "      <td>0.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-10-01 00:57:46</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-10-01 00:58:16</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-10-01 00:58:46</th>\n",
       "      <td>104.0</td>\n",
       "      <td>0.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-10-01 00:59:16</th>\n",
       "      <td>64.0</td>\n",
       "      <td>0.21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Activity  White Light\n",
       "2015-10-01 00:57:16      98.0         0.68\n",
       "2015-10-01 00:57:46       0.0         0.13\n",
       "2015-10-01 00:58:16       0.0         0.13\n",
       "2015-10-01 00:58:46     104.0         0.08\n",
       "2015-10-01 00:59:16      64.0         0.21"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aligned_act_df.head(5)\n",
    "# aligned_act_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process skin temperature file\n",
    "Skin temperature is stored in a zipped file per subject per night which contains about 10 excel files for each part of the body.\n",
    "\n",
    "**We have to take care of lots of human errors on the file names and contents.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Glob the `\"Input/Skin Temperature\"` folder to get a list of file names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def process_one_st_file(st_file, measure_types=['Forehead', 'Fingertip', 'Abdomen']):\n",
    "    \"\"\"\n",
    "    Extract epoch data from one skin temperature zip file for one patient, store into dataframe, convert to \n",
    "    proper datatypes and remove NaN.\n",
    "    \n",
    "    Args:\n",
    "        st_file: a zip file containing skin temperature measurement for one patient\n",
    "        measure_types: the different sides of the patient with temperature measurement\n",
    "    Return:\n",
    "        pandas dataframe containing the epoch data\n",
    "    \"\"\"\n",
    "    # base_dir = \"./Input/Skin Temperature\"\n",
    "    base_dir = tempfile.TemporaryDirectory()\n",
    "    one_st_df = pd.DataFrame()\n",
    "    \n",
    "    with zipfile.ZipFile(st_file) as st_zip:\n",
    "        for name in st_zip.namelist():\n",
    "            one_measure_df = pd.DataFrame()\n",
    "            for measure in measure_types:\n",
    "                records = []\n",
    "                patient_id, mea_type, night = \"\", \"\", \"\"\n",
    "                file_pattern = \"(?i).*(\" + measure  + \")_.*xlsx\"\n",
    "                if re.search(file_pattern, name):\n",
    "                    # print(name)\n",
    "                    file_name = st_zip.extract(name, path=base_dir.name)\n",
    "                    print(\"processing {0} ...\".format(file_name))\n",
    "                    wb = xlrd.open_workbook(file_name)\n",
    "                    sheet = wb.sheet_by_index(0)\n",
    "                    # print(sheet.nrows)\n",
    "                    row_ix = 0\n",
    "                    col_time =0; col_temp = 1; is_found = False\n",
    "                    while row_ix < sheet.nrows:                    #for row_ix in range(sheet.nrows):\n",
    "                        # print(sheet.cell(row_ix, 0))\n",
    "#                         if sheet.cell(row_ix, 0).ctype == xlrd.XL_CELL_TEXT and \\\n",
    "#                            \"Description\" in sheet.cell(row_ix, 0).value:\n",
    "#                             desc = sheet.cell(row_ix, 1).value\n",
    "#                             m = re.search(r\"([a-zA-Z]+)_(.*)_(N\\d)\", desc)\n",
    "#                             if m:\n",
    "#                                 mea_type = m.group(1)\n",
    "#                                 patient_id = m.group(2)\n",
    "#                                 night = m.group(3)\n",
    "#                                 print(mea_type, patient_id, night)\n",
    "                            # else: print(\"can't get description\")\n",
    "                        while sheet.cell(row_ix, col_time).ctype == xlrd.XL_CELL_DATE and not is_found:\n",
    "                            #print(sheet.cell(row_ix, col_temp).)\n",
    "                            if (sheet.cell(row_ix, col_temp).ctype == xlrd.XL_CELL_TEXT and \\\n",
    "                                \"C\" in sheet.cell(row_ix, col_temp).value) or \\\n",
    "                               (sheet.cell(row_ix, col_temp).ctype == xlrd.XL_CELL_NUMBER):\n",
    "                                is_found = True\n",
    "                            else:\n",
    "                                row_ix += 1; col_time += 1; col_temp += 1\n",
    "                        if is_found and not sheet.cell(row_ix, col_time).ctype == xlrd.XL_CELL_EMPTY:\n",
    "                            #print(sheet.cell(row_ix, col_time))\n",
    "                            datetime_value = xlrd.xldate_as_tuple(sheet.cell(row_ix, col_time).value, wb.datemode)\n",
    "                            temperature = sheet.cell(row_ix, col_temp).value\n",
    "                            if sheet.cell(row_ix, col_temp).ctype == xlrd.XL_CELL_TEXT and \"C\" in temperature:\n",
    "                                # temperature = temperature[:-2]\n",
    "                                temperature = float(temperature[:-2])\n",
    "                            records.append(tuple((datetime.datetime(*datetime_value), temperature)))\n",
    "                        \n",
    "                        row_ix += 1\n",
    "#                             break\n",
    "                if len(records) > 0:\n",
    "                    one_measure_df = pd.DataFrame.from_records(records)\n",
    "                    one_measure_df.columns = [\"Datetime\", \"Temperature\"]\n",
    "                    if len(patient_id) < 2:\n",
    "                        # print(\"can't get description\")\n",
    "                        m = re.search(r\".*/(.*)_(N\\d).*\", st_file)\n",
    "                        if m:\n",
    "                            mea_type = measure\n",
    "                            patient_id = m.group(1)\n",
    "                            night = m.group(2)                            \n",
    "                    # one_measure_df[\"Patient_id\"] = patient_id\n",
    "                    one_measure_df[\"Measure_type\"] = mea_type\n",
    "                    # one_measure_df[\"Night\"] = night\n",
    "                    one_st_df = one_st_df.append(one_measure_df, ignore_index=True)\n",
    "        \n",
    "    base_dir.cleanup()\n",
    "    return one_st_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def process_multi_st_files(st_file_list, \n",
    "            measure_types=['Forehead', 'Fingertip', 'Chest', 'Forearm', 'Upperarm', 'Hand', 'Scapula', 'Abdomen', \n",
    "                           'Upperleg', 'Calf', 'Foot', 'Toe']):\n",
    "    \"\"\"\n",
    "    Process multiple Skin Temperature files for different patients and extract each epoch data for each patient\n",
    "\n",
    "    Args:\n",
    "        st_file_list: a list of zip files containing skin temperature measurement for different patients\n",
    "        measure_types: the different sides of the patient with temperature measurement\n",
    "    Return:\n",
    "        pandas dataframe containing the epoch data\n",
    "    \"\"\"\n",
    "#     file_pattern = \"*\" + night_type + \".zip\"\n",
    "#     st_file_list = glob.glob(path + file_pattern)\n",
    "    st_df = pd.DataFrame()\n",
    "    for st_file in st_file_list:\n",
    "        one_st_df = process_one_st_file(st_file, measure_types)\n",
    "        st_df = st_df.append(one_st_df, ignore_index=True)\n",
    "        \n",
    "    # grouped by Datetime and measure_type\n",
    "    if len(st_df) > 0:\n",
    "        st_df = st_df.groupby(['Datetime', 'Measure_type'], as_index=False).mean()\n",
    "        st_df = st_df.pivot(index='Datetime', columns='Measure_type', values='Temperature')\n",
    "        st_df.index.name = None\n",
    "\n",
    "    # drop duplicated entries\n",
    "    # st_df.drop_duplicates(inplace=True)\n",
    "    return st_df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "st_file_list = glob.glob(\"./Input/Skin Temperature/*INS_WI_011*.zip\")\n",
    "len(st_file_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing /tmp/tmpdbdp2hxb/INS_WI_011_N1/1437 FOREHEAD_INS_WI_011_N1.xlsx ...\n",
      "processing /tmp/tmpdbdp2hxb/INS_WI_011_N1/1438 CHEST_INS_WI_011_N1.xlsx ...\n",
      "processing /tmp/tmpdbdp2hxb/INS_WI_011_N1/1439 UPPERARM_INS_WI_011_N1.xlsx ...\n",
      "processing /tmp/tmpdbdp2hxb/INS_WI_011_N1/ABDOMEN_INS_WI_011_N1 .xlsx ...\n",
      "processing /tmp/tmpdbdp2hxb/INS_WI_011_N1/CALF_INS_WI_011_N1 .xlsx ...\n",
      "processing /tmp/tmpdbdp2hxb/INS_WI_011_N1/FINGERTIP_INS_WI_011_N1 .xlsx ...\n",
      "processing /tmp/tmpdbdp2hxb/INS_WI_011_N1/FOOT_INS_WI_011_N1 .xlsx ...\n",
      "processing /tmp/tmpdbdp2hxb/INS_WI_011_N1/FOREARM_INS_WI_011_N1 .xlsx ...\n",
      "processing /tmp/tmpdbdp2hxb/INS_WI_011_N1/HAND_INS_WI_011_N1 .xlsx ...\n",
      "processing /tmp/tmpdbdp2hxb/INS_WI_011_N1/SCAPULA_INS_WI_011_N1 .xlsx ...\n",
      "processing /tmp/tmpdbdp2hxb/INS_WI_011_N1/TOE_INS_WI_011_N1 .xlsx ...\n",
      "processing /tmp/tmpdbdp2hxb/INS_WI_011_N1/UPPERLEG_INS_WI_011_N1 .xlsx ...\n"
     ]
    }
   ],
   "source": [
    "st_df = process_multi_st_files(st_file_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Align ST dataframe to staging dataframe by resampling to 30s interval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def align_st_df(staging_df, st_df):\n",
    "    \"\"\"\n",
    "    Align ST dataframe to staging dataframe by resampling to 30S interval\n",
    "    Args:\n",
    "        staging_df:\n",
    "        st_df:\n",
    "    Return:\n",
    "        aligned_st_df:\n",
    "    \"\"\"\n",
    "    if (st_df.index[1] - st_df.index[0]).seconds > 30:\n",
    "        start = (staging_df.index.min() - offsets.Second(60)).strftime('%Y-%m-%d %H:%M:%S')\n",
    "        # st_df = st_df / 2\n",
    "    else:\n",
    "        start = (staging_df.index.min() - offsets.Second(30)).strftime('%Y-%m-%d %H:%M:%S')\n",
    "    end = (staging_df.index.max()).strftime('%Y-%m-%d %H:%M:%S')\n",
    "    \n",
    "    aligned_st_df = st_df[start:end]\n",
    "    # check if ST data available to align with sleep staging data   \n",
    "    if len(aligned_st_df) == 0: return None\n",
    "    \n",
    "    if (aligned_st_df.index[1] - aligned_st_df.index[0]).seconds > 30:\n",
    "        aligned_st_df = aligned_st_df.resample('30S', base=staging_df.index.min().second, closed='right', label='right').ffill()\n",
    "    else:\n",
    "        aligned_st_df = aligned_st_df.resample('30S', base=staging_df.index.min().second, closed='right', label='right').mean()\n",
    "#     aligned_hr_df.columns = aligned_hr_df.columns.droplevel(1)\n",
    "    \n",
    "    return aligned_st_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "aligned_st_df = align_st_df(staging_df, st_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process all the required files to extract data for a given subject\n",
    "We define a function to extract all the measurements for a given subject. \n",
    "\n",
    "We need to check if the measurement is available after being aligned with sleep staging. If **NOT**, not to process for that subject and return **`None`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_data_per_subject(subject=\"INS_WI_008\", hr=True, st=True, act=True,\n",
    "                st_types=['Forehead', 'Fingertip', 'Chest', 'Forearm', 'Upperarm', 'Hand', 'Scapula', 'Abdomen', \n",
    "                           'Upperleg', 'Calf', 'Foot', 'Toe']):\n",
    "    \"\"\"\n",
    "    Extract actigraphy, skin temperature, heart rate and PSG scoring for a given subject\n",
    "    \n",
    "    Args:\n",
    "        subject: given one subject ID\n",
    "        hr, st, act: indicator whether the measurement is processed\n",
    "        st_type: list of sites for skin temperature\n",
    "    Return:\n",
    "        pandas dataframe containing the required data\n",
    "    \"\"\"\n",
    "    staging_path = \"./Input/Sleep stages/\" + \"INS \" + subject[-3:] + \"*.txt\"\n",
    "    act_path = \"./Input/Actigraphy/\" + subject + \"*.csv\"\n",
    "    st_path = \"./Input/Skin Temperature/\" + subject + \"*.zip\"\n",
    "    hr_path = \"./Input/HRV/\" + subject[-3:] + \"*.txt\"\n",
    "    staging_list = glob.glob(staging_path)\n",
    "    if len(staging_list) == 0: return None       \n",
    "    if act:\n",
    "        act_list = glob.glob(act_path)\n",
    "        if len(act_list) == 0: return None       \n",
    "    if st:\n",
    "        st_list = glob.glob(st_path)\n",
    "        if len(st_list) == 0: return None\n",
    "    if hr:\n",
    "        hr_list =  glob.glob(hr_path)\n",
    "        if len(hr_list) == 0: return None\n",
    "    \n",
    "    if len(staging_list) == 1: staging_df = process_one_staging_file(staging_list[0])\n",
    "    if act and len(act_list) == 1:\n",
    "        act_df = process_one_act_file(act_list[0])\n",
    "        if isinstance(act_df, type(None)): return None\n",
    "        aligned_act_df = align_act_df(staging_df, act_df)\n",
    "        if isinstance(aligned_act_df, type(None)): return None        \n",
    "    if hr and len(hr_list) == 1:\n",
    "        hr_df = process_one_hr_file(hr_list[0])\n",
    "        if isinstance(hr_df, type(None)): return None\n",
    "        aligned_hr_df = align_hr_df(staging_df, hr_df)\n",
    "        if isinstance(aligned_hr_df, type(None)): return None\n",
    "    if st and len(st_list) > 0: \n",
    "        st_df = process_multi_st_files(st_list, measure_types=st_types)\n",
    "        if isinstance(st_df, type(None)): return None\n",
    "        aligned_st_df = align_st_df(staging_df, st_df)\n",
    "        if isinstance(aligned_st_df, type(None)): return None        \n",
    "            \n",
    "    \n",
    "    if act and hr and st: combined_df = staging_df.join(aligned_act_df).join(aligned_hr_df).join(aligned_st_df)\n",
    "    elif hr and st: combined_df = staging_df.join(aligned_hr_df).join(aligned_st_df)\n",
    "#     return staging_df, aligned_act_df, aligned_st_df, aligned_hr_df\n",
    "    return combined_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "combined_df = extract_data_per_subject('INS_WI_039', act=False)\n",
    "# staging_df, aligned_act_df, aligned_st_df, aligned_hr_df = extract_data_per_subject()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data extraction, alignment to sleep staging data for multiple subjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_data_multi_subjects(subjects=['INS_WI_008', 'INS_WI_012'], hr=True, st=True, act=True,\n",
    "                    st_types=['Forehead', 'Fingertip', 'Chest', 'Forearm', 'Upperarm', 'Hand', 'Scapula', 'Abdomen', \n",
    "                           'Upperleg', 'Calf', 'Foot', 'Toe']):\n",
    "    \"\"\"\n",
    "    Extract actigraphy, skin temperature, heart rate and PSG scoring for a given subject list\n",
    "    \n",
    "    Args:\n",
    "        subjects: a list containing the patient_id\n",
    "    Return:\n",
    "        pandas dataframe containing the required data\n",
    "    \"\"\"\n",
    "    subjects_df = pd.DataFrame()\n",
    "    for subject in subjects:\n",
    "        one_subject_df = extract_data_per_subject(subject, hr, st, act, st_types)\n",
    "        if not isinstance(one_subject_df, type(None)):\n",
    "            subjects_df = subjects_df.append(one_subject_df)#, ignore_index=True)\n",
    "        \n",
    "    return subjects_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing ./Input/Sleep stages/INS 001-Events.txt ...\n",
      "Processing ./Input/HRV/001, INSEKG_RR Intervals.txt...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/qfen8290/miniconda3/lib/python3.5/site-packages/pandas/core/ops.py:533: PerformanceWarning: Adding/subtracting array of DateOffsets to Series not vectorized\n",
      "  \"Series not vectorized\", PerformanceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing /tmp/tmph1gox5s8/INS_WI_001_N2/1242 Chest_INS_WI_001_N2.xlsx ...\n",
      "processing /tmp/tmph1gox5s8/INS_WI_001_N2/1242 Forehead_INS_WI_001_N2.xlsx ...\n",
      "processing /tmp/tmph1gox5s8/INS_WI_001_N2/1242_UpperArm_INS_WI_001_N2.xlsx ...\n",
      "processing /tmp/tmph1gox5s8/INS_WI_001_N2/1247 Scapula_INS_WI_001_N2.xlsx ...\n",
      "processing /tmp/tmph1gox5s8/INS_WI_001_N2/1248 Forearm_INS_WI_001_N2.xlsx ...\n",
      "processing /tmp/tmph1gox5s8/INS_WI_001_N2/1249 Hand_INS_WI_001_N2.xlsx ...\n",
      "processing /tmp/tmph1gox5s8/INS_WI_001_N2/1250 Fingertip_INS_WI_001_N2.xlsx ...\n",
      "processing /tmp/tmph1gox5s8/INS_WI_001_N2/1251 Abdomen_INS_WI_001_N2.xlsx ...\n",
      "processing /tmp/tmph1gox5s8/INS_WI_001_N2/1252 Calf_INS_WI_001_N2.xlsx ...\n",
      "processing /tmp/tmph1gox5s8/INS_WI_001_N2/1253 Foot_INS_WI_001_N2.xlsx ...\n",
      "processing /tmp/tmph1gox5s8/INS_WI_001_N2/1254 Toe_INS_WI_001_N2.xlsx ...\n",
      "processing /tmp/tmpc97q_64i/INS_WI_001_N1/Abdomen_INS_WI_001_N1.xlsx ...\n",
      "processing /tmp/tmpc97q_64i/INS_WI_001_N1/Calf_INS_WI_001_N1.xlsx ...\n",
      "processing /tmp/tmpc97q_64i/INS_WI_001_N1/Chest_INS_WI_001_N1.xlsx ...\n",
      "processing /tmp/tmpc97q_64i/INS_WI_001_N1/Fingertip_INS_WI_001_N1.xlsx ...\n",
      "processing /tmp/tmpc97q_64i/INS_WI_001_N1/Foot_INS_WI_001_N1.xlsx ...\n",
      "processing /tmp/tmpc97q_64i/INS_WI_001_N1/Forearm_INS_WI_001_N1.xlsx ...\n",
      "processing /tmp/tmpc97q_64i/INS_WI_001_N1/Forehead_INS_WI_001_N1.xlsx ...\n",
      "processing /tmp/tmpc97q_64i/INS_WI_001_N1/Hand_INS_WI_001_N1.xlsx ...\n",
      "processing /tmp/tmpc97q_64i/INS_WI_001_N1/Scapula_INS_WI_001_N1.xlsx ...\n",
      "processing /tmp/tmpc97q_64i/INS_WI_001_N1/Toe_INS_WI_001_N1.xlsx ...\n",
      "processing /tmp/tmpc97q_64i/INS_WI_001_N1/Upperarm_INS_WI_001_N1.xlsx ...\n",
      "processing /tmp/tmpc97q_64i/INS_WI_001_N1/Upperleg_INS_WI_001_N1.xlsx ...\n"
     ]
    }
   ],
   "source": [
    "combined_df = extract_data_multi_subjects(subjects=['INS_WI_001'], act=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 889 entries, 2015-09-02 22:49:52 to 2015-09-03 06:13:52\n",
      "Data columns (total 16 columns):\n",
      "Patient_id    889 non-null object\n",
      "Staging       889 non-null object\n",
      "HR_mean       801 non-null float64\n",
      "HR_stdev      800 non-null float64\n",
      "Abdomen       888 non-null float64\n",
      "Calf          888 non-null float64\n",
      "Chest         888 non-null float64\n",
      "Fingertip     888 non-null float64\n",
      "Foot          888 non-null float64\n",
      "Forearm       888 non-null float64\n",
      "Forehead      888 non-null float64\n",
      "Hand          888 non-null float64\n",
      "Scapula       888 non-null float64\n",
      "Toe           888 non-null float64\n",
      "Upperarm      888 non-null float64\n",
      "Upperleg      888 non-null float64\n",
      "dtypes: float64(14), object(2)\n",
      "memory usage: 118.1+ KB\n"
     ]
    }
   ],
   "source": [
    "combined_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data extraction and process for subjects with Actigraphy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing ./Input/Sleep stages/INS 004-Events.txt ...\n",
      "Processing ./Input/Actigraphy/INS_WI_004_26_08_2015_6_00_00_PM_BL_AEM.csv...\n",
      "Processing ./Input/HRV/004, INSEKG_RR Intervals.txt...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/qfen8290/miniconda3/lib/python3.5/site-packages/pandas/core/ops.py:533: PerformanceWarning: Adding/subtracting array of DateOffsets to Series not vectorized\n",
      "  \"Series not vectorized\", PerformanceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing /tmp/tmpjtjlryco/INS_WI_004_N2/1314 Forehead_INS_WI_004_N2.xlsx ...\n",
      "processing /tmp/tmpjtjlryco/INS_WI_004_N2/1315 Chest_INS_WI_004_N2.xlsx ...\n",
      "processing /tmp/tmpjtjlryco/INS_WI_004_N2/1316 UpperArm_INS_WI_004_N2.xlsx ...\n",
      "processing /tmp/tmpjtjlryco/INS_WI_004_N2/1317 Scapula_INS_WI_004_N2.xlsx ...\n",
      "processing /tmp/tmpjtjlryco/INS_WI_004_N2/1318 Forearm_INS_WI_004_N2.xlsx ...\n",
      "processing /tmp/tmpjtjlryco/INS_WI_004_N2/1319 Hand_INS_WI_004_N2.xlsx ...\n",
      "processing /tmp/tmpjtjlryco/INS_WI_004_N2/1320 Fingertip_INS_WI_004_N2.xlsx ...\n",
      "processing /tmp/tmpjtjlryco/INS_WI_004_N2/1321 Abdomen_INS_WI_004_N2.xlsx ...\n",
      "processing /tmp/tmpjtjlryco/INS_WI_004_N2/1322 Upperleg_INS_WI_004_N2.xlsx ...\n",
      "processing /tmp/tmpjtjlryco/INS_WI_004_N2/1323 Calf_INS_WI_004_N2.xlsx ...\n",
      "processing /tmp/tmpjtjlryco/INS_WI_004_N2/1325 Foot_INS_WI_004_N2.xlsx ...\n",
      "processing /tmp/tmpjtjlryco/INS_WI_004_N2/1326 Toe_INS_WI_004_N2.xlsx ...\n",
      "processing /tmp/tmp88np_k2h/INS_WI_004_N1/Abdomen_INS_WI_004_N1.xlsx ...\n",
      "processing /tmp/tmp88np_k2h/INS_WI_004_N1/Calf_INS_WI_004_N1.xlsx ...\n",
      "processing /tmp/tmp88np_k2h/INS_WI_004_N1/Chest_INS_WI_004_N1.xlsx ...\n",
      "processing /tmp/tmp88np_k2h/INS_WI_004_N1/Fingertip_INS_WI_004_N1.xlsx ...\n",
      "processing /tmp/tmp88np_k2h/INS_WI_004_N1/Foot_INS_WI_004_N1.xlsx ...\n",
      "processing /tmp/tmp88np_k2h/INS_WI_004_N1/Forearm_INS_WI_004_N1.xlsx ...\n",
      "processing /tmp/tmp88np_k2h/INS_WI_004_N1/Forehead_INS_WI_004_N1.xlsx ...\n",
      "processing /tmp/tmp88np_k2h/INS_WI_004_N1/Hand_INS_WI_004_N1.xlsx ...\n",
      "processing /tmp/tmp88np_k2h/INS_WI_004_N1/Scapula_INS_WI_004_N1.xlsx ...\n",
      "processing /tmp/tmp88np_k2h/INS_WI_004_N1/Toe_INS_WI_004_N1.xlsx ...\n",
      "processing /tmp/tmp88np_k2h/INS_WI_004_N1/UpperArm_INS_WI_004_N1.xlsx ...\n",
      "processing /tmp/tmp88np_k2h/INS_WI_004_N1/Upperleg_INS_WI_004_N1.xlsx ...\n",
      "Processing ./Input/Sleep stages/INS 007-Events.txt ...\n",
      "Processing ./Input/Actigraphy/INS_WI_007_4_02_2016_6_00_00_PM_New_Analysis.csv...\n",
      "Processing ./Input/HRV/007, INSEKG_RR Intervals.txt...\n",
      "processing /tmp/tmpyqwa8kxu/INS_WI_007_N1/Abdomen_INS_WI_007_N1.xlsx ...\n",
      "processing /tmp/tmpyqwa8kxu/INS_WI_007_N1/Calf_INS_WI_007_N1.xlsx ...\n",
      "processing /tmp/tmpyqwa8kxu/INS_WI_007_N1/Chest_INS_WI_007_N1.xlsx ...\n",
      "processing /tmp/tmpyqwa8kxu/INS_WI_007_N1/Fingertip_INS_WI_007_N1.xlsx ...\n",
      "processing /tmp/tmpyqwa8kxu/INS_WI_007_N1/Foot_INS_WI_007_N1.xlsx ...\n",
      "processing /tmp/tmpyqwa8kxu/INS_WI_007_N1/Forearm_INS_WI_007_N1.xlsx ...\n",
      "processing /tmp/tmpyqwa8kxu/INS_WI_007_N1/Forehead_INS_WI_007_N1.xlsx ...\n",
      "processing /tmp/tmpyqwa8kxu/INS_WI_007_N1/Hand_INS_WI_007_N1.xlsx ...\n",
      "processing /tmp/tmpyqwa8kxu/INS_WI_007_N1/Scapula_INS_WI_007_N1.xlsx ...\n",
      "processing /tmp/tmpyqwa8kxu/INS_WI_007_N1/Toe_INS_WI_007_N1.xlsx ...\n",
      "processing /tmp/tmpyqwa8kxu/INS_WI_007_N1/Upperarm_INS_WI_007_N1.xlsx ...\n",
      "processing /tmp/tmpyqwa8kxu/INS_WI_007_N1/Upperleg_INS_WI_007_N1.xlsx ...\n",
      "processing /tmp/tmp2wn2b7ln/INS_WI_007_N2/Abdomen_INS_WI_007_N2.xlsx ...\n",
      "processing /tmp/tmp2wn2b7ln/INS_WI_007_N2/Calf_INS_WI_007_N2.xlsx ...\n",
      "processing /tmp/tmp2wn2b7ln/INS_WI_007_N2/Chest_INS_WI_007_N2.xlsx ...\n",
      "processing /tmp/tmp2wn2b7ln/INS_WI_007_N2/Fingertip_INS_WI_007_N2.xlsx ...\n",
      "processing /tmp/tmp2wn2b7ln/INS_WI_007_N2/Foot_INS_WI_007_N2.xlsx ...\n",
      "processing /tmp/tmp2wn2b7ln/INS_WI_007_N2/Forearm_INS_WI_007_N2.xlsx ...\n",
      "processing /tmp/tmp2wn2b7ln/INS_WI_007_N2/Forehead_INS_WI_007_N2.xlsx ...\n",
      "processing /tmp/tmp2wn2b7ln/INS_WI_007_N2/Hand_INS_WI_007_N2.xlsx ...\n",
      "processing /tmp/tmp2wn2b7ln/INS_WI_007_N2/Scapula_INS_WI_007_N2.xlsx ...\n",
      "processing /tmp/tmp2wn2b7ln/INS_WI_007_N2/Toe_INS_WI_007_N2.xlsx ...\n",
      "processing /tmp/tmp2wn2b7ln/INS_WI_007_N2/Upperarm_INS_WI_007_N2.xlsx ...\n",
      "processing /tmp/tmp2wn2b7ln/INS_WI_007_N2/Upperleg_INS_WI_007_N2.xlsx ...\n",
      "Processing ./Input/Sleep stages/INS 011-Events.txt ...\n",
      "Processing ./Input/Actigraphy/INS_WI_011_20_09_2015_9_00_00_AM_BL_AEM.csv...\n",
      "Processing ./Input/HRV/011, INSEKG_RR Intervals.txt...\n",
      "processing /tmp/tmp1o4lnjw7/INS_WI_011_N1/1437 FOREHEAD_INS_WI_011_N1.xlsx ...\n",
      "processing /tmp/tmp1o4lnjw7/INS_WI_011_N1/1438 CHEST_INS_WI_011_N1.xlsx ...\n",
      "processing /tmp/tmp1o4lnjw7/INS_WI_011_N1/1439 UPPERARM_INS_WI_011_N1.xlsx ...\n",
      "processing /tmp/tmp1o4lnjw7/INS_WI_011_N1/ABDOMEN_INS_WI_011_N1 .xlsx ...\n",
      "processing /tmp/tmp1o4lnjw7/INS_WI_011_N1/CALF_INS_WI_011_N1 .xlsx ...\n",
      "processing /tmp/tmp1o4lnjw7/INS_WI_011_N1/FINGERTIP_INS_WI_011_N1 .xlsx ...\n",
      "processing /tmp/tmp1o4lnjw7/INS_WI_011_N1/FOOT_INS_WI_011_N1 .xlsx ...\n",
      "processing /tmp/tmp1o4lnjw7/INS_WI_011_N1/FOREARM_INS_WI_011_N1 .xlsx ...\n",
      "processing /tmp/tmp1o4lnjw7/INS_WI_011_N1/HAND_INS_WI_011_N1 .xlsx ...\n",
      "processing /tmp/tmp1o4lnjw7/INS_WI_011_N1/SCAPULA_INS_WI_011_N1 .xlsx ...\n",
      "processing /tmp/tmp1o4lnjw7/INS_WI_011_N1/TOE_INS_WI_011_N1 .xlsx ...\n",
      "processing /tmp/tmp1o4lnjw7/INS_WI_011_N1/UPPERLEG_INS_WI_011_N1 .xlsx ...\n",
      "Processing ./Input/Sleep stages/INS 041-Events.txt ...\n",
      "Processing ./Input/Actigraphy/INS_WI_041_15_03_2016_11_59_00_AM_bl_aem.csv...\n",
      "Processing ./Input/HRV/041, INSEKG_RR Intervals.txt...\n",
      "processing /tmp/tmp38zdhw64/INS_WI_041_N1/2223 Forehead_INS_WI_041_N1.xlsx ...\n",
      "processing /tmp/tmp38zdhw64/INS_WI_041_N1/2224 Chest_INS_WI_041_N1.xlsx ...\n",
      "processing /tmp/tmp38zdhw64/INS_WI_041_N1/2225 UpperArm_INS_WI_041_N1.xlsx ...\n",
      "processing /tmp/tmp38zdhw64/INS_WI_041_N1/2226 Scapula_INS_WI_041_N1.xlsx ...\n",
      "processing /tmp/tmp38zdhw64/INS_WI_041_N1/2228 Hand_INS_WI_041_N1.xlsx ...\n",
      "processing /tmp/tmp38zdhw64/INS_WI_041_N1/2229 Fingertip_INS_WI_041_N1.xlsx ...\n",
      "processing /tmp/tmp38zdhw64/INS_WI_041_N1/2230 Abdomen_INS_WI_041_N1.xlsx ...\n",
      "processing /tmp/tmp38zdhw64/INS_WI_041_N1/2231 UpperLeg_INS_WI_041_N1.xlsx ...\n",
      "processing /tmp/tmp38zdhw64/INS_WI_041_N1/2232 Calf_INS_WI_041_N1.xlsx ...\n",
      "processing /tmp/tmp38zdhw64/INS_WI_041_N1/2233 Foot_INS_WI_041_N1.xlsx ...\n",
      "processing /tmp/tmp38zdhw64/INS_WI_041_N1/2234 Toe_INS_WI_041_N1.xlsx ...\n",
      "processing /tmp/tmp38zdhw64/INS_WI_041_N1/2227 Forearm_INS_WI_041_N1.xlsx ...\n"
     ]
    }
   ],
   "source": [
    "# subject list with ACT available - totally 20 subjects\n",
    "subject_list = ['INS_WI_008','INS_WI_012','INS_WI_013','INS_WI_017','INS_WI_019','INS_WI_020','INS_WI_021','INS_WI_022','INS_WI_025',\n",
    "                'INS_WI_030','INS_WI_032','INS_WI_034','INS_WI_035', 'INS_WI_037','INS_WI_038', 'INS_WI_040', 'INS_WI_004','INS_WI_007'\n",
    "                ,'INS_WI_011','INS_WI_041']\n",
    "subjects_df = extract_data_multi_subjects(subject_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Data extraction and process for subjects without Actigraphy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing ./Input/Sleep stages/INS 085-Events.txt ...\n",
      "Processing ./Input/HRV/085, INSEKG_RR Intervals.txt...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/qfen8290/miniconda3/lib/python3.5/site-packages/pandas/core/ops.py:533: PerformanceWarning: Adding/subtracting array of DateOffsets to Series not vectorized\n",
      "  \"Series not vectorized\", PerformanceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing /tmp/tmpqrwwknex/INS_WI_085_N1/Abdomen_INS_WI_085_N1.xlsx ...\n",
      "processing /tmp/tmpqrwwknex/INS_WI_085_N1/Calf_INS_WI_085_N1.xlsx ...\n",
      "processing /tmp/tmpqrwwknex/INS_WI_085_N1/Chest_INS_WI_085_N1.xlsx ...\n",
      "processing /tmp/tmpqrwwknex/INS_WI_085_N1/Fingertip_INS_WI_085_N1.xlsx ...\n",
      "processing /tmp/tmpqrwwknex/INS_WI_085_N1/Foot_INS_WI_085_N1.xlsx ...\n",
      "processing /tmp/tmpqrwwknex/INS_WI_085_N1/Forearm_INS_WI_085_N1.xlsx ...\n",
      "processing /tmp/tmpqrwwknex/INS_WI_085_N1/Forehead_INS_WI_085_N1.xlsx ...\n",
      "processing /tmp/tmpqrwwknex/INS_WI_085_N1/Hand_INS_WI_085_N1.xlsx ...\n",
      "processing /tmp/tmpqrwwknex/INS_WI_085_N1/Scapula_INS_WI_085_N1.xlsx ...\n",
      "processing /tmp/tmpqrwwknex/INS_WI_085_N1/Toe_INS_WI_085_N1.xlsx ...\n",
      "processing /tmp/tmpqrwwknex/INS_WI_085_N1/Upperarm_INS_WI_085_N1.xlsx ...\n",
      "processing /tmp/tmpqrwwknex/INS_WI_085_N1/Upperleg_INS_WI_085_N1.xlsx ...\n",
      "Processing ./Input/Sleep stages/INS 089-Events.txt ...\n",
      "Processing ./Input/HRV/089, INSEKG_RR Intervals.txt...\n",
      "processing /tmp/tmphi6o5zc2/INS_WI_089_N1/3957 Forehead_INS_WI_089_N1.xlsx ...\n",
      "processing /tmp/tmphi6o5zc2/INS_WI_089_N1/3958 Chest_INS_WI_089_N1.xlsx ...\n",
      "processing /tmp/tmphi6o5zc2/INS_WI_089_N1/3959 Upperarm_INS_WI_089_N1.xlsx ...\n",
      "processing /tmp/tmphi6o5zc2/INS_WI_089_N1/3960 Scapula_INS_WI_089_N1.xlsx ...\n",
      "processing /tmp/tmphi6o5zc2/INS_WI_089_N1/3961 Forearm_INS_WI_089_N1.xlsx ...\n",
      "processing /tmp/tmphi6o5zc2/INS_WI_089_N1/3962 Hand_INS_WI_089_N1.xlsx ...\n",
      "processing /tmp/tmphi6o5zc2/INS_WI_089_N1/3963 Fingertip_INS_WI_089_N1.xlsx ...\n",
      "processing /tmp/tmphi6o5zc2/INS_WI_089_N1/3964 Abdomen_INS_WI_089_N1.xlsx ...\n",
      "processing /tmp/tmphi6o5zc2/INS_WI_089_N1/3965 Upperleg_INS_WI_089_N1.xlsx ...\n",
      "processing /tmp/tmphi6o5zc2/INS_WI_089_N1/3966 Foot_INS_WI_089_N1.xlsx ...\n",
      "processing /tmp/tmphi6o5zc2/INS_WI_089_N1/3967 Toe_INS_WI_089_N1.xlsx ...\n"
     ]
    }
   ],
   "source": [
    "subject_list = ['INS_WI_085','INS_WI_089']\n",
    "subjects_df = extract_data_multi_subjects(subject_list, act=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Feature engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute the DPG for skin temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df2['ST_Distal'] = df2[['Fingertip', 'Toe', 'Hand', 'Foot']].mean(axis=1)\n",
    "df2['ST_Proximal'] = df2[['Abdomen', 'Chest', 'Upperarm', 'Upperleg']].mean(axis=1)\n",
    "df2['ST_DPG'] = df2['ST_Proximal'] - df2['ST_Distal']"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
